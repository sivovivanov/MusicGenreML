{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southern-cutting",
   "metadata": {},
   "source": [
    "# CS985MLDAGroup21\n",
    "<p> Ian Richardson 202074007 </p>\n",
    "<p> Fraser Bayne 202053049 </p>\n",
    "<p> Slav Ivanov 201645797 </p>\n",
    "<p> Lora Kiosseva 202082329 </p>\n",
    "\n",
    "- A description of the model and solution that you employed for the final set of predictions. <br>\n",
    "<p> The model used in the end was a OneVersesRest classifier in code block 27, this also writes out the predictions to the file foo.csv </p> <br>\n",
    "\n",
    "- A justification for why you choose this architecture and solution including: how you came up with the approach, why you selected or modified input variables, explaining what worked and did not work, and what other models were tried.<br>\n",
    "<p> We used a number of different models to test against each other with a validation set of the data as well as optimiser algorithms to set the parameters of these models, all of this is kept in the file (blocks 15-25) </p> <br>\n",
    "\n",
    "When processing the data, we tried a number of approaches such as: factorizing the years into decades and one hot encoding this, grouping some of the values into quntiles of data, scaling the data and dropping certain columns and using over and under sampling to increase the ammount of training data, although all of these would make our final predictions very off and get worse scores on the Kaggle competition, this code was the best combination of preprocessing and column dropping <br>\n",
    "\n",
    "We also elected to drop all rows in the training with uncommon genres, our cut-off point was less than 6 occurrences. This will improve our training so that it is not getting thrown off unnecessarily by these uncommon genres <br>\n",
    "\n",
    "The scores from our own validation set where much higher that that of the Kaggle competition, possibly due to overfitting the data. We found that using over and under sampling of the data we could get very high scores in the validation (upwards of 0.8-0.9) but these would not translate to the Kaggle scoring (getting around 0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "republican-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nutritional-middle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composite-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Models\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpha-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "introductory-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Optimise\n",
    "from skopt import gp_minimize\n",
    "from skopt.utils import cook_initial_point_generator\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automotive-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train_set = pd.read_csv(\"./dataset/CS98XClassificationTrain.csv\")\n",
    "test_set = pd.read_csv(\"./dataset/CS98XClassificationTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "provincial-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = np.array(test_set[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afraid-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with NaNs\n",
    "train_set = train_set.dropna()\n",
    "# Drop all irrelevant columns \"Id\", \"title\", \"artist\", \"spch\", \"nrgy\", \"live\", \"dB\", \"bpm\"\n",
    "train_set = train_set.drop(columns=[\"Id\", \"title\", \"artist\", \"spch\", \"nrgy\", \"live\", \"dB\", \"bpm\"])\n",
    "test_set = test_set.drop(columns=[\"Id\", \"title\", \"artist\", \"spch\", \"nrgy\", \"live\", \"dB\", \"bpm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abstract-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we want to predict\n",
    "predict = \"top genre\"\n",
    "train_set = train_set.groupby(predict).filter(lambda x : len(x)>=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vertical-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get everything except what we want to predict\n",
    "X = np.array(train_set.drop([predict], 1)).astype(np.float64)\n",
    "# Column we want to predict\n",
    "y = np.array(train_set[predict])\n",
    "# Actual test dataset as numpy array\n",
    "X_test = np.array(test_set).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bizarre-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled data\n",
    "std_scaler = StandardScaler()\n",
    "X_scaled = std_scaler.fit_transform(X)\n",
    "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_scaled, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "controversial-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-scaled data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dramatic-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Model Testing\n",
    "# --------------\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "young-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ovo():\n",
    "    model = OneVsOneClassifier(SVC(kernel=\"rbf\", degree=2, C=1.1, gamma=0.3,\n",
    "                                   probability=True, decision_function_shape = \"ovo\",\n",
    "                                   random_state=42))\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    models.append((\"ovo\", model))\n",
    "    print(\"> One Versus One Classifier\", model.score(X_val_scaled, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "phantom-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ovr():\n",
    "    model = OneVsRestClassifier(LinearSVC(dual=False, fit_intercept=False,\n",
    "                                          max_iter=10000,\n",
    "                                          random_state=42,))\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    models.append((\"ovr\", model))\n",
    "    print(\"> One Versus Rest Classifier\", model.score(X_val_scaled, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "infinite-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_tree():\n",
    "    model = DecisionTreeClassifier(max_depth=2, splitter=\"best\",\n",
    "                                   max_features=\"auto\", criterion=\"gini\",\n",
    "                                   random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    models.append((\"dec_tree\", model))\n",
    "    print(\"> Decision Tree Classifier\", model.score(X_val, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "atmospheric-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_for():\n",
    "    model = RandomForestClassifier(n_estimators=155, max_depth=2,\n",
    "                                                 bootstrap=True, n_jobs=-1,\n",
    "                                                 warm_start=True, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    models.append((\"rnd_for\", model))\n",
    "    print(\"> Random Forest Classifier\", model.score(X_val, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fifty-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada():\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3, max_features=\"auto\",),\n",
    "                               n_estimators=40,\n",
    "                               algorithm=\"SAMME.R\",\n",
    "                               learning_rate=0.2,\n",
    "                               random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    models.append((\"ada\", model))\n",
    "    print(\"> AdaBoost Classifier\", model.score(X_val, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pending-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbc():\n",
    "    model = GradientBoostingClassifier(max_depth=4, n_estimators=50,\n",
    "                                       learning_rate=1.0, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    models.append((\"gbc\", model))\n",
    "    print(\"> Gradient Boosting Classifier\", model.score(X_val, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "handmade-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlpc():\n",
    "    model = MLPClassifier(activation = \"logistic\", solver=\"adam\",\n",
    "                          max_iter=500, alpha=0.5,\n",
    "                          learning_rate_init=0.1, warm_start=True,\n",
    "                          learning_rate=\"invscaling\", shuffle=True,\n",
    "                          random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    models.append((\"mlpc\", model))\n",
    "    print(\"> Multi-Layer Perceptron Classifier\", model.score(X_val_scaled, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "healthy-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnc():\n",
    "    model = KNeighborsClassifier(n_neighbors=15, weights=\"uniform\",\n",
    "                                 n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    models.append((\"knnc\", model))\n",
    "    print(\"> K-Nearest Neighbors Classifier\", model.score(X_val, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "local-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting():\n",
    "    model = VotingClassifier(estimators=models,\n",
    "        voting='hard')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    print(\"> Voting Classifier\", model.score(X_val_scaled, y_val),\n",
    "          \"- f1\", f1_score(y_val, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "variable-coalition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns ['year' 'dnce' 'val' 'dur' 'acous' 'pop']\n",
      "> One Versus One Classifier 0.4875 - f1 0.37784090909090917\n",
      "> One Versus Rest Classifier 0.4875 - f1 0.3940199335548173\n",
      "> Decision Tree Classifier 0.4625 - f1 0.35241355569155447\n",
      "> Random Forest Classifier 0.5 - f1 0.38053168635875395\n",
      "> AdaBoost Classifier 0.5 - f1 0.3975821718327439\n",
      "> Multi-Layer Perceptron Classifier 0.5 - f1 0.3825213903743315\n",
      "> K-Nearest Neighbors Classifier 0.475 - f1 0.37164505233847267\n",
      "> Voting Classifier 0.5125 - f1 0.39080159705159695\n"
     ]
    }
   ],
   "source": [
    "print(\"Using columns\", train_set.columns.values[:len(train_set.columns.values)-1])\n",
    "ovo()\n",
    "ovr()\n",
    "dec_tree()\n",
    "rnd_for()\n",
    "ada()\n",
    "mlpc()\n",
    "knnc()\n",
    "voting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "center-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Real Prediction\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sweet-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(LinearSVC(dual=False, fit_intercept=False,\n",
    "                                      max_iter=10000,\n",
    "                                      random_state=42))\n",
    "\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "csv = np.stack((id_column, y_pred), axis=1)\n",
    "csv = np.vstack((np.array([\"Id\",\"top genre\"]), csv))\n",
    "np.savetxt(\"./foo.csv\", csv, fmt='%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "convinced-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Optimisation\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "editorial-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    model = RandomForestClassifier(n_estimators=155, max_depth=2,\n",
    "                                   bootstrap=True, n_jobs=-1,\n",
    "                                   warm_start=True, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    return -model.score(X_val_scaled, y_val)\n",
    "\n",
    "def bayesian_opt():\n",
    "    lhs_maximin = cook_initial_point_generator(\"lhs\", criterion=\"maximin\")\n",
    "\n",
    "    res = gp_minimize(f,\n",
    "                      [Integer(1, 100, transform='identity'),\n",
    "                       Integer(10, 1000, transform='identity'),\n",
    "                       Real(0.1, 100.0, transform='identity')],\n",
    "                      x0=[[3, 40, 0.2]],\n",
    "                      xi=0.000001,\n",
    "                      #kappa=0.001,\n",
    "                      acq_func='EI', acq_optimizer='sampling',\n",
    "                      n_calls=100, n_initial_points=10, initial_point_generator=lhs_maximin,\n",
    "                      verbose = False,\n",
    "                      noise = 1e-10,\n",
    "                      random_state = 42)\n",
    "\n",
    "    return (res.x, res.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-brook",
   "metadata": {},
   "source": [
    "This written out CSV (foo.csv) gets a Kaggle competition score of 0.30357"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
